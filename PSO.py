#mostly generated by copilot in 15 min, some corrections done but this was not the main focus of the project

import random
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.animation as animation
import tqdm

random.seed(42)
np.random.seed(42)

class Particle:
    def __init__(self, position):
        self.position = position
        self.velocity = [random.uniform(-1, 1) for _ in range(len(position))]
        self.best_position = position
        self.best_fitness = float('inf')

    def update_velocity(self, global_best_position, inertia_weight, cognitive_weight, social_weight):
        for i in range(len(self.velocity)): 
            #NOTE: An improvement idea might be to rescale by how good my best position is 
            #relative to how good the social best position is, slower convergence but better quality likely
        
            ### random.random() makes it overfly some times
            cognitive_component = cognitive_weight * random.random() * (self.best_position[i] - self.position[i])
            social_component = social_weight * random.random() * (global_best_position[i] - self.position[i])
            self.velocity[i] = inertia_weight * self.velocity[i] + cognitive_component + social_component

    def update_position(self):
        for i in range(len(self.position)):
            self.position[i] += self.velocity[i]

    def evaluate_fitness(self, neg_fitness_function):
        neg_fitness = neg_fitness_function(self.position)[0]
        if neg_fitness < self.best_fitness:
            self.best_fitness = neg_fitness
            self.best_position = self.position

class Optimization_problem:
    def __init__(self, neg_fitness_function, arguments, name=None):
        self.neg_fitness_function = neg_fitness_function
        self.arguments=arguments
        self.name=name

def particle_swarm_optimization(opt_problem, num_particles=100, num_iterations=100, inertia_weight=0.6, cognitive_weight=0.95/10, social_weight=0.9/10, initial_mus_sigma=None, Animation=False):
    "initial position is an array, returns best_positions,scores as lists"

    dimensions=opt_problem.arguments
    neg_fitness_function=opt_problem.neg_fitness_function

    if initial_mus_sigma:
        (mu,_)=initial_mus_sigma
        particles = [Particle(mu+10**(-2)*np.random.randn(2)) for _ in range(num_particles)] 
    else:
        particles = [Particle(np.random.uniform(-20, 20,size=(dimensions))) for _ in range(num_particles)]
        mu=np.array([0,0])

    # Store the best positions for visualization
    best_positions = []
    scores=[]

    #global global_best_position
    global_best_position=mu

    if not Animation:
        scores.append(neg_fitness_function(global_best_position))
        best_positions.append(global_best_position)

        for i in tqdm.tqdm(range(num_iterations), desc=f"running PSO for {opt_problem.name}"):
            for particle in particles:
                particle.update_velocity(global_best_position, inertia_weight, cognitive_weight, social_weight)
                particle.update_position()
                particle.evaluate_fitness(neg_fitness_function)

                if particle.best_fitness < neg_fitness_function(global_best_position):
                    global_best_position = particle.best_position

            # Store the best position for this iteration
            best_positions.append(global_best_position)
            scores.append(neg_fitness_function(global_best_position))

    else: ### NOTE: probably broken due to global_best_position, but not used in the study
        fig, ax = plt.subplots()
        def update(i):
            #global global_best_position
            for particle in particles:
                particle.update_velocity(global_best_position, inertia_weight, cognitive_weight, social_weight)
                particle.update_position()
                particle.evaluate_fitness(neg_fitness_function)

                if particle.best_fitness < neg_fitness_function(global_best_position):
                    global_best_position = particle.best_position

            # Store the best position for this iteration
            best_positions.append(global_best_position)

            ax.clear()
            if i % 1==0: #recalculate only some times to not make it too messy could be an idea but needs more work
                positions = [particle.position for particle in particles]

                min_x = min(position[0] for position in positions)
                max_x = max(position[0] for position in positions)
                min_y = min(position[1] for position in positions)
                max_y = max(position[1] for position in positions)

            x = np.linspace(min_x-1, max_x+1, 100)
            y = np.linspace(min_y-1, max_y+1, 100)
            X, Y = np.meshgrid(x, y)
            Z = np.array([neg_fitness_function([x, y]) for x, y in zip(np.ravel(X), np.ravel(Y))])
            Z = Z.reshape(X.shape)

            ax.contour(X, Y, Z, levels=20)
            ax.scatter(*zip(*positions), color='red')
            ax.plot([10],[2], '^g')

            ax.set_title('Iteration number: {}'.format(i))
        
        ani = animation.FuncAnimation(fig, update, frames=num_iterations, interval=100, repeat=False)
        plt.show()

    return best_positions, scores

# Example usage
def neg_fitness_function(position):
    "something which should be minimized!"
    return (10-position[0])**2 + (2-position[1])**2

if __name__ == "__main__": # a test case

    opt_problem=Optimization_problem(neg_fitness_function, 2, None)
    best_positions, scores = particle_swarm_optimization(opt_problem, num_particles=50, num_iterations=100)
    print("Best position:", best_positions[-1]) 

